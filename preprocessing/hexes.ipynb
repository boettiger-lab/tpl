{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70ecae6-ed3d-47ab-8450-f500ab2f0362",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59760595-9aaa-49ee-b825-09c0ffab9af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cng.utils import *\n",
    "from cng.h3 import *\n",
    "from ibis import _\n",
    "import os\n",
    "from osgeo import gdal\n",
    "from minio import Minio\n",
    "import streamlit \n",
    "from datetime import timedelta\n",
    "import geopandas as gpd\n",
    "\n",
    "# Get signed URLs to access license-controlled layers\n",
    "key = st.secrets[\"MINIO_KEY\"]\n",
    "secret = st.secrets[\"MINIO_SECRET\"]\n",
    "client = Minio(\"minio.carlboettiger.info\", key, secret)\n",
    "\n",
    "con = ibis.duckdb.connect(extensions = [\"spatial\", \"h3\"])\n",
    "endpoint = os.getenv(\"AWS_S3_ENDPOINT\", \"minio.carlboettiger.info\")\n",
    "duckdb_install_h3()\n",
    "\n",
    "set_secrets(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b086a1a-af23-487b-923d-fca595a19111",
   "metadata": {},
   "source": [
    "#### Converting data to hexes at zoom 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c7474-7ee6-48b0-8242-6d29a28841f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h3_from_geom(con, name, cols, zoom = 8):\n",
    "    \"\"\"\n",
    "    Computes hexes directly from geometry.\n",
    "    \"\"\"\n",
    "    cols = \", \".join(cols) if isinstance(cols, list) else cols\n",
    "    con.raw_sql(f'''\n",
    "    CREATE OR REPLACE TEMP TABLE t2 AS\n",
    "    SELECT {cols},\n",
    "           h3_polygon_wkt_to_cells_string(ST_Force2D(dump.geom), {zoom}) AS h{zoom}\n",
    "    FROM (\n",
    "        SELECT {cols}, UNNEST(ST_Dump(geom)) AS dump\n",
    "        FROM {name}\n",
    "    )\n",
    "    ''')\n",
    "    con.sql(f'''\n",
    "        SELECT {cols}, UNNEST(h{zoom}) AS h{zoom},\n",
    "        ST_GeomFromText(h3_cell_to_boundary_wkt(UNNEST(h{zoom}))) AS geom\n",
    "        FROM t2\n",
    "    ''').to_parquet(f\"{name}_h3_z{zoom}.parquet\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a33f5-3647-40bc-9c03-f145c60b95d1",
   "metadata": {},
   "source": [
    "# TPL Conservation Almanac\n",
    "\n",
    "Hexing this data at zoom 8 level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa510b-3434-4ded-88c7-e06844ee503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpl = client.get_presigned_url(\n",
    "    \"GET\",\n",
    "    \"shared-tpl\",\n",
    "    \"tpl.parquet\",\n",
    "    expires=timedelta(hours=2),\n",
    ")\n",
    "\n",
    "cols = ['fid', 'TPL_ID', 'State', 'County', 'Municipality',\n",
    "       'Site_Name', 'Reported_Acres', 'Close_Year', 'Close_Date', 'Owner_Name',\n",
    "       'Owner_Type', 'Manager_Name', 'Manager_Type', 'Purchase_Type',\n",
    "       'EasementHolder_Name', 'EasementHolder_Type', 'Public_Access_Type',\n",
    "       'Purpose_Type', 'Duration_Type', 'Data_Provider', 'Data_Source',\n",
    "       'Source_Date', 'Data_Aggregator', 'Comments', 'Amount', 'Program_ID',\n",
    "       'Program_Name', 'Sponsor_ID', 'Sponsor_Name', 'Sponsor_Type']\n",
    "\n",
    "\n",
    "tpl_table = (con.read_parquet(tpl)\n",
    "             .mutate(geom = _.geom.convert(\"ESRI:102039\", \"EPSG:4326\"))\n",
    "            )\n",
    "\n",
    "con.create_table('tpl', tpl_table, overwrite=True)\n",
    "h3_from_geom(con, 'tpl', cols)\n",
    "\n",
    "client.fput_object(bucket_name = \"shared-tpl\",\n",
    "           object_name = \"tpl_h3_z8.parquet\",\n",
    "           file_path = \"tpl_h3_z8.parquet\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00cfe9-520c-4839-aeed-46a83b11ecce",
   "metadata": {},
   "source": [
    "# Census\n",
    "\n",
    "Getting polygons and FIPS codes from Census state, county, place, and subdivision data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec60670-4abc-4fc4-86ca-88a77ba69d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_url = \"s3://public-census/2024/state/2024_us_state.parquet\"\n",
    "county_url = \"s3://public-census/2024/county/2024_us_county.parquet\"\n",
    "\n",
    "state_file = '2024_us_state_h3_z8.parquet'\n",
    "county_temp_file = '2024_us_county_h3_z8_temp.parquet'\n",
    "county_file = '2024_us_county_h3_z8.parquet'\n",
    "city_file = '2024_us_places_subdivisions_h3_z8.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd589ad-5b03-41de-8936-c20091a937e1",
   "metadata": {},
   "source": [
    "#### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2ed94-740f-49cd-a041-50401b7c7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert shape file to parquet \n",
    "gdf = gpd.read_file('tl_2024_us_state.shp').to_crs('epsg:4326').rename_geometry('geom').rename(columns={\"GEOID\": \"FIPS\", \"STUSPS\":\"state\", \"NAME\":\"name\"})\n",
    "con.create_table('state_wkt', gdf, overwrite=True)\n",
    "\n",
    "# get geom (duckdb turns geodataframes into wkt)\n",
    "con.sql(\"\"\"\n",
    "SELECT * EXCLUDE geom,\n",
    "  ST_GeomFromWKB(geom) AS geom\n",
    "FROM state_wkt\n",
    "\"\"\").to_parquet(state_url)\n",
    "\n",
    "# convert to h3\n",
    "con.read_parquet(state_url, table_name = 'state')\n",
    "cols = ['STATE','name','FIPS']\n",
    "h3_from_geom(con, 'state', cols)\n",
    "\n",
    "# save file \n",
    "client.fput_object(bucket_name = \"public-census\",\n",
    "           file_path = \"state_h3_z8.parquet\",\n",
    "           object_name = f\"2024/state/{state_file}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39905b6-b0b6-46d0-a035-cd1ac0f43d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing state abbeviations for later\n",
    "state_ids = con.read_parquet(state_url).select('name','state','FIPS').rename(state_name = 'name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ea182-ac50-4ee8-a14b-5dcbcb14a044",
   "metadata": {},
   "source": [
    "#### County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3d43f-9ab8-4f3e-a981-51c5eca6f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# convert shape to parquet \n",
    "gdf = gpd.read_file('tl_2024_us_county.shp').to_crs('epsg:4326').rename_geometry('geom').drop('NAME',axis =1).rename(columns={\"GEOID\": \"FIPS\", \"NAMELSAD\":\"name\"})[['geom','name','FIPS','STATEFP']]\n",
    "con.create_table('county_wkt', gdf, overwrite=True)\n",
    "\n",
    "# convert to geom (duckdb turns geodataframes into wkt)\n",
    "con.sql(\"\"\"\n",
    "SELECT * EXCLUDE geom,\n",
    "  ST_GeomFromWKB(geom) AS geom\n",
    "FROM county_wkt\n",
    "\"\"\").to_parquet(county_url)\n",
    "\n",
    "# convert to h3\n",
    "con.read_parquet(county_url, table_name = 'county')\n",
    "cols = ['name','FIPS','STATEFP']\n",
    "h3_from_geom(con, 'county', cols)\n",
    "\n",
    "# save file \n",
    "client.fput_object(bucket_name = \"public-census\",\n",
    "           file_path = \"county_h3_z8.parquet\",\n",
    "           object_name = f\"2024/county/{county_temp_file}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a5023-45d7-4039-a078-4901ebdd3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a non hex version of counties to use as bounds in tpl app\n",
    "temp = con.read_parquet(county_url)\n",
    "(temp.left_join(state_ids, [temp.STATEFP == state_ids.FIPS]).drop('FIPS_right','STATEFP')\n",
    " .rename(county = 'name').select('FIPS','state','state_name','county','geom')\n",
    ").to_parquet(county_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7829daf-8333-4e35-83f6-0a2bbcd174fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get state abbeviations for counties\n",
    "county_geo = con.read_parquet(f\"s3://public-census/2024/county/{county_temp_file}\")\n",
    "county_geo.left_join(state_ids, [county_geo.STATEFP == state_ids.FIPS]).drop('FIPS_right','STATEFP').to_parquet(f\"s3://public-census/2024/county/{county_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e703812-5369-4bb3-857f-37ed946168e7",
   "metadata": {},
   "source": [
    "#### Cities (places + subdivisions)\n",
    "\n",
    "Note: Some cities are listed in both \"Places\" and \"Subdivisions\", so we will use `distinct()` to avoid duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e9a96-5fcb-409b-812c-b79f7a319eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_pattern = r\"(?i)\\s*(city|town|village|charter|municipality|Borough)\\b\"\n",
    "city_cols = [\"state\",\"county\",\"FIPS\",\"name\",'city']\n",
    "\n",
    "places_url = \"https://www2.census.gov/geo/docs/reference/codes2020/national_place_by_county2020.txt\"\n",
    "places_fips = (con.read_csv(places_url)\n",
    "               .rename(state = \"STATE\", county = \"COUNTYNAME\", city = \"PLACENAME\")\n",
    "               .mutate(name=_.city.re_replace(match_pattern, \"\").strip())\n",
    "               .mutate(FIPS = _.STATEFP + _.COUNTYFP)\n",
    "               .select(city_cols))\n",
    "\n",
    "subdivisions_url = \"https://www2.census.gov/geo/docs/reference/codes2020/national_cousub2020.txt\"\n",
    "subdivisions_fips = (con.read_csv(subdivisions_url)\n",
    "                     .rename(state = \"STATE\", county = \"COUNTYNAME\", city = \"COUSUBNAME\")\n",
    "                     .mutate(name=_.city.re_replace(match_pattern, \"\").strip())\n",
    "                     .mutate(FIPS = _.STATEFP + _.COUNTYFP)\n",
    "                     .select(city_cols))\n",
    "\n",
    "city_fips = places_fips.union(subdivisions_fips).distinct() #get unique -> some cities are listed in both places and subdivisions\n",
    "city_geo = city_fips.left_join(county_geo, 'FIPS').drop('FIPS_right','name_right','city') #get h3 from counties \n",
    "city_joined = city_geo.left_join(state_ids, [city_geo.STATEFP == state_ids.FIPS]).drop('FIPS_right','STATEFP','state_right')# get state ids \n",
    "city_joined.to_parquet(f\"s3://public-census/2024/places_subdivisions/{city_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62511665-7859-4997-98d8-ae7c08b64f46",
   "metadata": {},
   "source": [
    "# Landvote\n",
    "\n",
    "We want to join Landvote data with TPL Conservation Almanac, but Landvote doesn't have spatial data.\n",
    "\n",
    "However, we can join Landvote with Census data to get FIPS codes and hexes. \n",
    "- First, need to split up landvote into its 3 jurisdictions: state, county, and municipals\n",
    "- Join states with Census \"states\" to get state FIPS/hex\n",
    "- Join counties with Census \"counties\" to get county FIPS/hex\n",
    "- Join municipals with Census \"places\" and \"subdivisions\" to get county FIPS/hex\n",
    "- Then join all municipal, county, and state data back together!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ba16f-b876-48f0-b1c1-1d2e1b1d3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "landvote_csv = client.get_presigned_url(\n",
    "    \"GET\",\n",
    "    \"shared-tpl\",\n",
    "    \"landvote.csv\",\n",
    "    expires=timedelta(hours=2),\n",
    ")\n",
    "\n",
    "match_pattern = r\"(?i)\\s*(city|town|village|charter|municipality|Borough)\\b\"\n",
    "landvote = (con.read_csv(landvote_csv, ignore_errors=True)\n",
    "            .rename(jurisdiction = \"Jurisdiction Type\", state = \"State\")\n",
    "            .mutate(state = _.state.substitute({'Ore':'OR'}))\n",
    "            .mutate(name=_['Jurisdiction Name'].re_replace(match_pattern, \"\").strip())\n",
    "            .mutate(landvote_id=ibis.row_number().over())\n",
    "            .mutate(_['Conservation Funds Approved'].replace('$', '')\n",
    "                    .replace(',', '').cast('float').name('Conservation Funds Approved')))\n",
    "\n",
    "\n",
    "final_columns = ['landvote_id',\n",
    "    'FIPS',\n",
    "    'state',\n",
    "    'state_name',\n",
    "    'county',\n",
    "    'city',\n",
    "    'jurisdiction',\n",
    "    'Date',\n",
    "    'Description',\n",
    "    'Finance Mechanism',\n",
    "    '\"Other\" Comment',\n",
    "    'Purpose',\n",
    "    'Total Funds at Stake',\n",
    "    'Conservation Funds at Stake',\n",
    "    'Total Funds Approved',\n",
    "    'Conservation Funds Approved',\n",
    "    'Pass?',\n",
    "    'Status',\n",
    "    '% Yes',\n",
    "    '% No',\n",
    "    'Notes',\n",
    "    'Voted Acq. Measure',\n",
    "    'geom',\n",
    "    'h8']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89e4e6-1845-4842-baa4-aa6908a1cde1",
   "metadata": {},
   "source": [
    "#### State level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb7c0c-80bb-4d6d-9088-0877e365a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_geo = con.read_parquet(f\"s3://public-census/2024/state/{state_file}\")\n",
    "states = (landvote.filter(_.jurisdiction == \"State\")\n",
    "            .rename(state_name = \"Jurisdiction Name\")\n",
    "            .mutate(county = ibis.literal('None'))\n",
    "            .mutate(county_fips = ibis.literal('None'))\n",
    "            .mutate(city = ibis.literal('None')))\n",
    "\n",
    "landvote_state = (states.left_join(state_geo, [states.name.upper() == state_geo.name.upper()])\n",
    "                   .select(final_columns))\n",
    "\n",
    "#adding state ID and state name from the county/city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202f31a-5868-4e74-951e-23acb49f0bc7",
   "metadata": {},
   "source": [
    "#### County level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a792367-dcab-4869-94b4-6343a3204e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_geo = con.read_parquet(f\"s3://public-census/2024/county/{county_file}\")\n",
    "\n",
    "county_match_pattern = r\"(?i)\\s*(County)\\b\"\n",
    "\n",
    "counties = (landvote.filter(_.jurisdiction == \"County\")\n",
    "            .rename(county = \"Jurisdiction Name\")\n",
    "            .mutate(city = ibis.literal('None'))\n",
    "            .mutate(name=_.name.re_replace(county_match_pattern, \"\").strip()))\n",
    "\n",
    "landvote_county = (counties.left_join(county_geo, [counties.name.upper() == county_geo.name.upper(), \n",
    "                                                    counties.state == county_geo.state])\n",
    "                   .select(final_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca12e06-8d7f-4a50-906c-7dc02e370072",
   "metadata": {},
   "source": [
    "#### Municipal level\n",
    "\n",
    "Because there isn't a 1 to 1 match from municipals to Census data, we need to use both \"Places\" and \"Subdivisons\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81e457-00ba-4b01-86d7-cf46bec04edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "city_geo = con.read_parquet(f\"s3://public-census/2024/places_subdivisions/{city_file}\")\n",
    "\n",
    "municipals = landvote.filter(_.jurisdiction == \"Municipal\").rename(city = \"Jurisdiction Name\")\n",
    "\n",
    "landvote_city = (municipals.left_join(city_geo, [municipals.name.upper() == city_geo.name.upper(), \n",
    "                                                  municipals.state == city_geo.state])\n",
    "                 .inner_join(state_ids, [municipals.state == state_ids.state])\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d52d97b-ad14-4d04-89a8-79a813f80353",
   "metadata": {},
   "source": [
    "#### Joining all the landvote data with census\n",
    "Note: `landvote_joined` has more rows than `landvote` because some cities span multiple counties. Each additional county creates a new row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d481736-82f3-4be2-b5af-6280be5e9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "landvote_joined = landvote_city.union(landvote_county).union(landvote_state)\n",
    "landvote_joined.to_parquet(\"s3://shared-tpl/landvote_h3_z8.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbdacae-28cf-4335-b895-f1335749a6e3",
   "metadata": {},
   "source": [
    "#### And get a non-hex version of landvote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdc9d2-f195-427b-b1c6-08f1f5f90ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis.selectors as s\n",
    "\n",
    "state_geo = con.read_parquet(state_url)\n",
    "landvote_state = (states.left_join(state_geo, [states.name.upper() == state_geo.name.upper()])).select(final_columns[:-1])\n",
    "\n",
    "county_geo = con.read_parquet(county_url)\n",
    "landvote_county = (counties.left_join(county_geo, [counties.name.upper() == county_geo.county.upper(), \n",
    "                                                    counties.state == county_geo.state])).select(final_columns[:-1])\n",
    "\n",
    "city_fips = places_fips.union(subdivisions_fips).distinct() #get unique -> some cities are listed in both places and subdivisions\n",
    "city_geo = city_fips.left_join(county_geo, 'FIPS').select(~s.endswith('_right'))\n",
    "\n",
    "landvote_city = (municipals.left_join(city_geo, [municipals.name.upper() == city_geo.name.upper(), \n",
    "                                                  municipals.state == city_geo.state])\n",
    "                 ).select(final_columns[:-1])\n",
    "\n",
    "landvote_joined = landvote_city.union(landvote_county).union(landvote_state)\n",
    "landvote_joined.to_parquet(\"s3://shared-tpl/landvote_geom.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a207c-d560-4dab-8ec6-3fee24cb880b",
   "metadata": {},
   "source": [
    "# Join TPL Almanac with Landvote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e6648-d3ad-4e63-81a0-6f78f3b7584c",
   "metadata": {},
   "source": [
    "- Joining the data\n",
    "- Generate pmtiles -> converting h8 back to original polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2359bf0-1f3b-4af4-a96f-301dde56d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining data\n",
    "landvote_parquet = client.get_presigned_url(\n",
    "    \"GET\",\n",
    "    \"shared-tpl\",\n",
    "    \"landvote_h3_z8.parquet\",\n",
    "    expires=timedelta(hours=2),\n",
    ")\n",
    "\n",
    "landvote = (con.read_parquet(landvote_parquet)\n",
    "            .rename(FIPS_county = \"FIPS\",\n",
    "                    measure_status = \"Status\", measure_purpose = \"Purpose\",measure_amount = 'Conservation Funds Approved')\n",
    "            .mutate(measure_year = _.Date.year()).drop('Date','geom'))\n",
    "\n",
    "tpl_parquet = client.get_presigned_url(\n",
    "    \"GET\",\n",
    "    \"shared-tpl\",\n",
    "    \"tpl_h3_z8.parquet\",\n",
    "    expires=timedelta(hours=2),\n",
    ")\n",
    "\n",
    "tpl_drop_cols = ['Reported_Acres','Close_Date','EasementHolder_Name',\n",
    "        'Data_Provider','Data_Source','Data_Aggregator',\n",
    "        'Program_ID','Sponsor_ID']\n",
    "tpl = con.read_parquet(tpl_parquet).mutate(h8 = _.h8.lower()).drop(tpl_drop_cols)\n",
    "        \n",
    "\n",
    "select_cols = ['fid','TPL_ID','landvote_id',\n",
    "'state','state_name','county',\n",
    " 'FIPS_county','city','jurisdiction',\n",
    " 'Close_Year', 'Site_Name',\n",
    " 'Owner_Name','Owner_Type',\n",
    " 'Manager_Name','Manager_Type',\n",
    " 'Purchase_Type','EasementHolder_Type',\n",
    " 'Public_Access_Type','Purpose_Type',\n",
    " 'Duration_Type','Amount',\n",
    " 'Program_Name','Sponsor_Name',\n",
    " 'Sponsor_Type','measure_year',\n",
    " 'measure_status','measure_purpose',\n",
    " 'measure_amount']\n",
    "\n",
    "# joining all data\n",
    "database = (\n",
    "  tpl.drop('State','County')\n",
    "  .left_join(landvote, \"h8\").drop('h8_right')\n",
    ").select(select_cols).distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d5165-1b9f-4faf-9291-855d51698adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting original polygons back \n",
    "tpl_geom_url = client.get_presigned_url(\n",
    "    \"GET\",\n",
    "    \"shared-tpl\",\n",
    "    \"tpl.parquet\",\n",
    "    expires=timedelta(hours=2),\n",
    ")\n",
    "\n",
    "tpl_geom = con.read_parquet(tpl_geom_url).select('geom','TPL_ID','fid').mutate(geom = _.geom.convert(\"ESRI:102039\", \"EPSG:4326\"))\n",
    "\n",
    "database = (database.inner_join(tpl_geom, [database.TPL_ID == tpl_geom.TPL_ID, database.fid == tpl_geom.fid])\n",
    "            # .mutate(id=ibis.row_number().over())\n",
    "            # .drop('TPL_ID','fid','landvote_id')\n",
    "           )\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb698f-3925-4aa6-8b89-56a6ee839312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to parquet/pmtiles \n",
    "database.to_parquet(\"s3://shared-tpl/tpl_almanac_landvote_geom.parquet\")\n",
    "database.execute().set_crs('epsg:4326').to_file('tpl_almanac_landvote_geom.geojson')\n",
    "\n",
    "to_pmtiles('tpl_almanac_landvote_geom.geojson', 'tpl_almanac_landvote_geom.pmtiles', options = ['--extend-zooms-if-still-dropping'])\n",
    "s3_cp('tpl_almanac_landvote_geom.pmtiles', \"s3://shared-tpl/tpl_almanac_landvote_geom.pmtiles\", \"minio\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
